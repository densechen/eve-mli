{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eve: Making Learning Interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a checkpoint form PyTorch to Eve\n",
    "\n",
    "We provide a script to load a checkpoint from PyTorch net to Eve net in few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth does not contains a 'state_dict' keytry to take the whole checkpoint as state_dict.\n",
      "Please specify a kep map between eve and legacy.\n",
      "You should pick up the paired key in eve and legacy and build a dict like: {'eve_key': 'legacy_key'}, then directly skip the unpaired one.\n",
      "In most cases, the key order will not be changed, it is not a heavy work to do this.\n",
      "key of /media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\n",
      "['classifier.bias',\n",
      " 'classifier.weight',\n",
      " 'features.0.weight',\n",
      " 'features.1.bias',\n",
      " 'features.1.num_batches_tracked',\n",
      " 'features.1.running_mean',\n",
      " 'features.1.running_var',\n",
      " 'features.1.weight',\n",
      " 'features.10.weight',\n",
      " 'features.11.bias',\n",
      " 'features.11.num_batches_tracked',\n",
      " 'features.11.running_mean',\n",
      " 'features.11.running_var',\n",
      " 'features.11.weight',\n",
      " 'features.14.weight',\n",
      " 'features.15.bias',\n",
      " 'features.15.num_batches_tracked',\n",
      " 'features.15.running_mean',\n",
      " 'features.15.running_var',\n",
      " 'features.15.weight',\n",
      " 'features.17.weight',\n",
      " 'features.18.bias',\n",
      " 'features.18.num_batches_tracked',\n",
      " 'features.18.running_mean',\n",
      " 'features.18.running_var',\n",
      " 'features.18.weight',\n",
      " 'features.3.weight',\n",
      " 'features.4.bias',\n",
      " 'features.4.num_batches_tracked',\n",
      " 'features.4.running_mean',\n",
      " 'features.4.running_var',\n",
      " 'features.4.weight',\n",
      " 'features.7.weight',\n",
      " 'features.8.bias',\n",
      " 'features.8.num_batches_tracked',\n",
      " 'features.8.running_mean',\n",
      " 'features.8.running_var',\n",
      " 'features.8.weight']\n",
      "====================\n",
      "key of /media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth\n",
      "['task_module.cdt1.0.voltage_threshold',\n",
      " 'task_module.cdt1.1.alpha',\n",
      " 'task_module.cdt1.1.bit_width',\n",
      " 'task_module.cdt2.0.voltage_threshold',\n",
      " 'task_module.cdt2.1.alpha',\n",
      " 'task_module.cdt2.1.bit_width',\n",
      " 'task_module.cdt3.0.voltage_threshold',\n",
      " 'task_module.cdt3.1.alpha',\n",
      " 'task_module.cdt3.1.bit_width',\n",
      " 'task_module.cdt4.0.voltage_threshold',\n",
      " 'task_module.cdt4.1.alpha',\n",
      " 'task_module.cdt4.1.bit_width',\n",
      " 'task_module.cdt5.0.voltage_threshold',\n",
      " 'task_module.cdt5.1.alpha',\n",
      " 'task_module.cdt5.1.bit_width',\n",
      " 'task_module.cdt6.0.voltage_threshold',\n",
      " 'task_module.cdt6.1.alpha',\n",
      " 'task_module.cdt6.1.bit_width',\n",
      " 'task_module.clssifier.bias',\n",
      " 'task_module.clssifier.weight',\n",
      " 'task_module.conv1.0.weight',\n",
      " 'task_module.conv1.1.bias',\n",
      " 'task_module.conv1.1.num_batches_tracked',\n",
      " 'task_module.conv1.1.running_mean',\n",
      " 'task_module.conv1.1.running_var',\n",
      " 'task_module.conv1.1.weight',\n",
      " 'task_module.conv2.0.weight',\n",
      " 'task_module.conv2.1.bias',\n",
      " 'task_module.conv2.1.num_batches_tracked',\n",
      " 'task_module.conv2.1.running_mean',\n",
      " 'task_module.conv2.1.running_var',\n",
      " 'task_module.conv2.1.weight',\n",
      " 'task_module.conv3.0.weight',\n",
      " 'task_module.conv3.1.bias',\n",
      " 'task_module.conv3.1.num_batches_tracked',\n",
      " 'task_module.conv3.1.running_mean',\n",
      " 'task_module.conv3.1.running_var',\n",
      " 'task_module.conv3.1.weight',\n",
      " 'task_module.conv4.0.weight',\n",
      " 'task_module.conv4.1.bias',\n",
      " 'task_module.conv4.1.num_batches_tracked',\n",
      " 'task_module.conv4.1.running_mean',\n",
      " 'task_module.conv4.1.running_var',\n",
      " 'task_module.conv4.1.weight',\n",
      " 'task_module.conv5.0.weight',\n",
      " 'task_module.conv5.1.bias',\n",
      " 'task_module.conv5.1.num_batches_tracked',\n",
      " 'task_module.conv5.1.running_mean',\n",
      " 'task_module.conv5.1.running_var',\n",
      " 'task_module.conv5.1.weight',\n",
      " 'task_module.conv6.0.weight',\n",
      " 'task_module.conv6.1.bias',\n",
      " 'task_module.conv6.1.num_batches_tracked',\n",
      " 'task_module.conv6.1.running_mean',\n",
      " 'task_module.conv6.1.running_var',\n",
      " 'task_module.conv6.1.weight']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid key map of NoneType. Follow the introduction above to generate a valid key map first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-287ec1d23f75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEveCifar10Vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m eve.utils.load_weight_from_legacy_checkpoint(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlegacy_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/utils/legacy.py\u001b[0m in \u001b[0;36mload_weight_from_legacy_checkpoint\u001b[0;34m(m, legacy_checkpoint, eve_checkpoint, key_map, map_location)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"key of {legacy_checkpoint}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_state_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;34m\"Invalid key map of NoneType. Follow the introduction above \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \"to generate a valid key map first.\")\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid key map of NoneType. Follow the introduction above to generate a valid key map first."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import eve\n",
    "import eve.cores\n",
    "import eve.app\n",
    "import eve.utils\n",
    "\n",
    "# import a evenet\n",
    "from eve.app import EveCifar10Vgg\n",
    "\n",
    "\n",
    "net = EveCifar10Vgg()\n",
    "\n",
    "eve.utils.load_weight_from_legacy_checkpoint(\n",
    "    net,\n",
    "    legacy_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the downloaded pytorch model\n",
    "    # the checkpoint of alexnet can be downloaded from https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    "    eve_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the path to store new model.\n",
    "    key_map=None, # NOTE: key_map is a dict which map the different names of weights between PyTorch and Eve.\n",
    "                  # Left to None at first time call, for that we haven't defined that. \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we do not have the key_map defined, we call `load_weight_from_legacy_checkpoint` will raise an error.\n",
    "Following the guidance of the above output, we can easy generate a key_map for specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map = {\n",
    "    'task_module.conv1.0.weight': 'features.0.weight',\n",
    "    'task_module.conv1.1.bias': 'features.1.bias',\n",
    "    'task_module.conv1.1.num_batches_tracked':\n",
    "    'features.1.num_batches_tracked',\n",
    "    'task_module.conv1.1.running_mean': 'features.1.running_mean',\n",
    "    'task_module.conv1.1.running_var': 'features.1.running_var',\n",
    "    'task_module.conv1.1.weight': 'features.1.weight',\n",
    "    'task_module.conv2.0.weight': 'features.3.weight',\n",
    "    'task_module.conv2.1.bias': 'features.4.bias',\n",
    "    'task_module.conv2.1.num_batches_tracked':\n",
    "    'features.4.num_batches_tracked',\n",
    "    'task_module.conv2.1.running_mean': 'features.4.running_mean',\n",
    "    'task_module.conv2.1.running_var': 'features.4.running_var',\n",
    "    'task_module.conv2.1.weight': 'features.4.weight',\n",
    "    'task_module.conv3.0.weight': 'features.7.weight',\n",
    "    'task_module.conv3.1.bias': 'features.8.bias',\n",
    "    'task_module.conv3.1.num_batches_tracked':\n",
    "    'features.8.num_batches_tracked',\n",
    "    'task_module.conv3.1.running_mean': 'features.8.running_mean',\n",
    "    'task_module.conv3.1.running_var': 'features.8.running_var',\n",
    "    'task_module.conv3.1.weight': 'features.8.weight',\n",
    "    'task_module.conv4.0.weight': 'features.10.weight',\n",
    "    'task_module.conv4.1.bias': 'features.11.bias',\n",
    "    'task_module.conv4.1.num_batches_tracked':\n",
    "    'features.11.num_batches_tracked',\n",
    "    'task_module.conv4.1.running_mean': 'features.11.running_mean',\n",
    "    'task_module.conv4.1.running_var': 'features.11.running_var',\n",
    "    'task_module.conv4.1.weight': 'features.11.weight',\n",
    "    'task_module.conv5.0.weight': 'features.14.weight',\n",
    "    'task_module.conv5.1.bias': 'features.15.bias',\n",
    "    'task_module.conv5.1.num_batches_tracked':\n",
    "    'features.15.num_batches_tracked',\n",
    "    'task_module.conv5.1.running_mean': 'features.15.running_mean',\n",
    "    'task_module.conv5.1.running_var': 'features.15.running_var',\n",
    "    'task_module.conv5.1.weight': 'features.15.weight',\n",
    "    'task_module.conv6.0.weight': 'features.17.weight',\n",
    "    'task_module.conv6.1.bias': 'features.18.bias',\n",
    "    'task_module.conv6.1.num_batches_tracked':\n",
    "    'features.18.num_batches_tracked',\n",
    "    'task_module.conv6.1.running_mean': 'features.18.running_mean',\n",
    "    'task_module.conv6.1.running_var': 'features.18.running_var',\n",
    "    'task_module.conv6.1.weight': 'features.18.weight',\n",
    "    'task_module.clssifier.bias': 'classifier.bias',\n",
    "    'task_module.clssifier.weight': 'classifier.weight',\n",
    "}\n",
    "# we also give the kep_map for each implemented methods.\n",
    "# key_map = eve.app.imagenet.alexnet.key_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, recall `load_weight_from_legacy_checkpoint` and deliver the key_map to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth does not contains a 'state_dict' keytry to take the whole checkpoint as state_dict.\n",
      "new checkpoint has been saved in /media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth.\n"
     ]
    }
   ],
   "source": [
    "eve.utils.load_weight_from_legacy_checkpoint(\n",
    "    net,\n",
    "    legacy_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the downloaded pytorch model\n",
    "    # the checkpoint of alexnet can be downloaded from https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    "    eve_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the path to store new model.\n",
    "    key_map=key_map, # NOTE: key_map is a dict which map the different names of weights between PyTorch and Eve.\n",
    "                  # Left to None at first time call, for that we haven't defined that. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load directly from converted eve-checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trainer via make and test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: trainer_cifar10_vgg ({'checkpoint_path': \"\n",
      " \"'/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth', \"\n",
      " \"'max_timesteps': 1, 'net_arch_kwargs': {'node': 'IfNode', 'node_kwargs': \"\n",
      " \"{'neuron_wise': False}, 'quan': 'SteQuan', 'quan_kwargs': {'neuron_wise': \"\n",
      " \"False, 'upgradable': False, 'max_bit_width': 8}, 'encoder': 'RateEncoder', \"\n",
      " \"'encoder_kwargs': {}}, 'optimizer_kwargs': {'optimizer': 'Adam', 'lr': \"\n",
      " \"0.001, 'betas': [0.99, 0.999], 'eps': 1e-08, 'weight_decay': 1e-05, \"\n",
      " \"'amsgrad': False, 'momentum': 0.9, 'nesterov': False}, 'data_kwargs': \"\n",
      " \"{'root': '/media/densechen/data/dataset', 'batch_size': 128, 'num_workers': \"\n",
      " \"4}, 'upgrader_kwargs': {}, 'kwargs': {'device': 'cuda:0'}})\")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "original accuracy: 0.9302808544303798\n",
      "no upgrader needed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import eve\n",
    "import eve.cores\n",
    "import eve.app\n",
    "import eve.utils\n",
    "\n",
    "# import a evenet\n",
    "from eve.app import make\n",
    "\n",
    "trainer = make(\n",
    "    id=\"trainer_cifar10_vgg\",\n",
    "    checkpoint_path=\"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\",\n",
    "    max_timesteps=1,\n",
    "    net_arch_kwargs={\n",
    "        \"node\": \"IfNode\",\n",
    "        \"node_kwargs\": {\n",
    "            \"neuron_wise\": False,\n",
    "        },\n",
    "        \"quan\": \"SteQuan\",\n",
    "        \"quan_kwargs\": {\n",
    "            \"neuron_wise\": False,\n",
    "            \"upgradable\": False,\n",
    "            \"max_bit_width\": 8, # NOTE: This max bit width argument will be convered by loading the checkpoint.\n",
    "        },\n",
    "        \"encoder\": \"RateEncoder\",\n",
    "        \"encoder_kwargs\": {}\n",
    "    },\n",
    "    optimizer_kwargs={\n",
    "        \"optimizer\":\n",
    "        \"Adam\",  # which kind of optimizer, SGD or Adam is supported current.\n",
    "        \"lr\": 0.001,  # learning rate\n",
    "        \"betas\": [0.99, 0.999],  # betas\n",
    "        \"eps\": 1e-8,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"amsgrad\": False,\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterov\": False,\n",
    "    },\n",
    "    data_kwargs={\n",
    "        \"root\": \"/media/densechen/data/dataset\",\n",
    "        \"batch_size\": 128,\n",
    "        \"num_workers\": 4,\n",
    "    },\n",
    "    upgrader_kwargs={},\n",
    "    kwargs={\n",
    "        \"device\": \"cuda:0\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
