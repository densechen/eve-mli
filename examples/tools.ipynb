{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eve: Making Learning Interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a checkpoint form PyTorch to Eve\n",
    "\n",
    "We provide a script to load a checkpoint from PyTorch net to Eve net in few steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer index 0\n",
      "Layer index 1\n",
      "Layer index 2\n",
      "Layer index 3\n",
      "Layer index 4\n",
      "Layer index 5\n",
      "Layer index 6\n",
      "/media/densechen/data/code/eve-mli/examples/checkpoint/alexnet-owt-4df8aa71.pth does not contains a 'state_dict' keytry to take the whole checkpoint as state_dict.\n",
      "new checkpoint has been saved in /media/densechen/data/code/eve-mli/examples/checkpoint/eve-alexnet-owt-4df8aa71.pth.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import eve\n",
    "import eve.cores\n",
    "import eve.app\n",
    "import eve.utils\n",
    "\n",
    "# import a evenet\n",
    "from eve.app.imagenet.alexnet import AlexNet\n",
    "\n",
    "\n",
    "net = AlexNet()\n",
    "\n",
    "eve.utils.load_weight_from_legacy_checkpoint(\n",
    "    net,\n",
    "    legacy_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/alexnet-owt-4df8aa71.pth\", # the downloaded pytorch model\n",
    "    # the checkpoint of alexnet can be downloaded from https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    "    eve_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-alexnet-owt-4df8aa71.pth\", # the path to store new model.\n",
    "    key_map=net.key_map, # NOTE: key_map is a dict which map the different names of weights between PyTorch and Eve.\n",
    "                  # Left to None at first time call, for that we haven't defined that. \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we do not have the key_map defined, we call `load_weight_from_legacy_checkpoint` will raise an error.\n",
    "Following the guidance of the above output, we can easy generate a key_map for specified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_map = {\n",
    "    'task_module.clssifier.bias': 'classifier.bias',\n",
    "    'task_module.clssifier.weight': 'classifier.weight',\n",
    "    'task_module.conv1.0.weight': 'features.0.weight',\n",
    "    'task_module.conv1.1.bias': 'features.1.bias',\n",
    "    'task_module.conv1.1.num_batches_tracked':\n",
    "    'features.1.num_batches_tracked',\n",
    "    'task_module.conv1.1.running_mean': 'features.1.running_mean',\n",
    "    'task_module.conv1.1.running_var': 'features.1.running_var',\n",
    "    'task_module.conv1.1.weight': 'features.1.weight',\n",
    "    'task_module.conv2.0.weight': 'features.3.weight',\n",
    "    'task_module.conv2.1.bias': 'features.4.bias',\n",
    "    'task_module.conv2.1.num_batches_tracked':\n",
    "    'features.4.num_batches_tracked',\n",
    "    'task_module.conv2.1.running_mean': 'features.4.running_mean',\n",
    "    'task_module.conv2.1.running_var': 'features.4.running_var',\n",
    "    'task_module.conv2.1.weight': 'features.4.weight',\n",
    "    'task_module.conv3.1.weight': 'features.7.weight',\n",
    "    'task_module.conv3.2.bias': 'features.8.bias',\n",
    "    'task_module.conv3.2.num_batches_tracked':\n",
    "    'features.8.num_batches_tracked',\n",
    "    'task_module.conv3.2.running_mean': 'features.8.running_mean',\n",
    "    'task_module.conv3.2.running_var': 'features.8.running_var',\n",
    "    'task_module.conv3.2.weight': 'features.8.weight',\n",
    "    'task_module.conv4.0.weight': 'features.10.weight',\n",
    "    'task_module.conv4.1.bias': 'features.11.bias',\n",
    "    'task_module.conv4.1.num_batches_tracked':\n",
    "    'features.11.num_batches_tracked',\n",
    "    'task_module.conv4.1.running_mean': 'features.11.running_mean',\n",
    "    'task_module.conv4.1.running_var': 'features.11.running_var',\n",
    "    'task_module.conv4.1.weight': 'features.11.weight',\n",
    "    'task_module.conv5.1.weight': 'features.14.weight',\n",
    "    'task_module.conv5.2.bias': 'features.15.bias',\n",
    "    'task_module.conv5.2.num_batches_tracked':\n",
    "    'features.15.num_batches_tracked',\n",
    "    'task_module.conv5.2.running_mean': 'features.15.running_mean',\n",
    "    'task_module.conv5.2.running_var': 'features.15.running_var',\n",
    "    'task_module.conv5.2.weight': 'features.15.weight',\n",
    "    'task_module.conv6.0.weight': 'features.17.weight',\n",
    "    'task_module.conv6.1.bias': 'features.18.bias',\n",
    "    'task_module.conv6.1.num_batches_tracked':\n",
    "    'features.18.num_batches_tracked',\n",
    "    'task_module.conv6.1.running_mean': 'features.18.running_mean',\n",
    "    'task_module.conv6.1.running_var': 'features.18.running_var',\n",
    "    'task_module.conv6.1.weight': 'features.18.weight',\n",
    "}\n",
    "# we also give the kep_map for each implemented methods.\n",
    "# key_map = eve.app.imagenet.alexnet.key_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, recall `load_weight_from_legacy_checkpoint` and deliver the key_map to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eve.utils.load_weight_from_legacy_checkpoint(\n",
    "    net,\n",
    "    legacy_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the downloaded pytorch model\n",
    "    # the checkpoint of alexnet can be downloaded from https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\n",
    "    eve_checkpoint=\n",
    "    \"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\", # the path to store new model.\n",
    "    key_map=key_map, # NOTE: key_map is a dict which map the different names of weights between PyTorch and Eve.\n",
    "                  # Left to None at first time call, for that we haven't defined that. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load directly from converted eve-checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\")[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a trainer via make and test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import eve\n",
    "import eve.cores\n",
    "import eve.app\n",
    "import eve.utils\n",
    "\n",
    "# import a evenet\n",
    "from eve.app import make\n",
    "\n",
    "trainer = make(\n",
    "    id=\"trainer_cifar10_vgg\",\n",
    "    checkpoint_path=\"/media/densechen/data/code/eve-mli/examples/checkpoint/eve-cifar10-vggsmall-zxd-93.4-8943fa3.pth\",\n",
    "    max_timesteps=1,\n",
    "    net_arch_kwargs={\n",
    "        \"node\": \"IfNode\",\n",
    "        \"node_kwargs\": {\n",
    "        },\n",
    "        \"quan\": \"SteQuan\",\n",
    "        \"quan_kwargs\": {\n",
    "            \"max_bits\": 8, # NOTE: This max bit width argument will be convered by loading the checkpoint.\n",
    "        },\n",
    "        \"encoder\": \"RateEncoder\",\n",
    "        \"encoder_kwargs\": {}\n",
    "    },\n",
    "    optimizer_kwargs={\n",
    "        \"optimizer\":\n",
    "        \"Adam\",  # which kind of optimizer, SGD or Adam is supported current.\n",
    "        \"lr\": 0.001,  # learning rate\n",
    "        \"betas\": [0.99, 0.999],  # betas\n",
    "        \"eps\": 1e-8,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"amsgrad\": False,\n",
    "        \"momentum\": 0.9,\n",
    "        \"nesterov\": False,\n",
    "    },\n",
    "    data_kwargs={\n",
    "        \"root\": \"/media/densechen/data/dataset\",\n",
    "        \"batch_size\": 128,\n",
    "        \"num_workers\": 4,\n",
    "    },\n",
    "    upgrader_kwargs={},\n",
    "    kwargs={\n",
    "        \"device\": \"cuda:0\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
