{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Features of Eve\n",
    "## Making learning interesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAS with RL\n",
    "\n",
    "Now, let's try some more interesting things with **Eve**.\n",
    "\n",
    "Let's begin with an example on minst, which use DDPG method to search for the best bit width for quantization\n",
    "network.\n",
    "\n",
    "First, let's import the necessary package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import difflib\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Although we do not import env here, \n",
    "# but it requires us to import the env to register the env to global.\n",
    "import eve.rl.envs\n",
    "\n",
    "import seaborn\n",
    "import torch\n",
    "from pprint import pprint\n",
    "from eve.rl.exp_manager import ExperimentManager\n",
    "from eve.rl.utils.utils import ALGOS, StoreDict\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "seaborn.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(algo='ddpg', env='FixedNas-v0', env_kwargs={'trainer_id': 'mnist', 'checkpoint_path': '/media/densechen/data/code/eve/examples/mnist.pt', 'max_timesteps': 1, 'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': {'device': 'cuda:0', 'root_dir': '/media/densechen/data/code/eve/examples'}}, eval_episodes=5, eval_freq=10000, gym_packages=[], hyperparams=None, log_folder='/media/densechen/data/code/eve/examples/logs', log_interval=-1, n_evaluations=20, n_jobs=1, n_startup_trials=10, n_timesteps=-1, n_trials=10, num_threads=-1, optimize_hyperparameters=False, pruner='median', sampler='tpe', save_freq=-1, save_replay_buffer=False, seed=-1, storage=None, study_name=None, tensorboard_log='/media/densechen/data/code/eve/examples/logs/', trained_agent='', truncate_last_trajectory=True, uuid=False, vec_env='dummy', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--algo\", \n",
    "                    help=\"RL Algorithm used to NAS searching.\",\n",
    "                    default=\"ddpg\",\n",
    "                    type=str,\n",
    "                    required=False,\n",
    "                    choices=list(ALGOS.keys()),\n",
    "                   )\n",
    "parser.add_argument(\"--env\",\n",
    "                    help=\"The environment used to wrapper trainer.\"\n",
    "                         \"Different environment will apply different\"\n",
    "                         \"reward function and interactive steps.\",\n",
    "                    default=\"FixedNas-v0\",\n",
    "                    type=str,\n",
    "                    required=False,\n",
    "                   )\n",
    "parser.add_argument(\"-tb\",\n",
    "                    \"--tensorboard-log\",\n",
    "                    help=\"Tensorboard log dir.\",\n",
    "                    default=\"/media/densechen/data/code/eve/examples/logs/\",\n",
    "                    type=str,\n",
    "                   )\n",
    "parser.add_argument(\"-i\",\n",
    "                    \"--trained_agent\",\n",
    "                    help=\"Path to a pretrained agent to continue training\",\n",
    "                    default=\"\",\n",
    "                    type=str,\n",
    "                   )\n",
    "parser.add_argument(\"--truncate-last-trajectory\",\n",
    "                    help=\"When using HER with online sampling the last\"\n",
    "                         \"trajectory in the replay buffer will be truncated\"\n",
    "                         \"after reloading the replay buffer.\",\n",
    "                    default=True,\n",
    "                    type=bool,\n",
    "                   )\n",
    "parser.add_argument(\"-n\",\n",
    "                    \"--n-timesteps\",\n",
    "                    help=\"Overwrite the number of timesteps\",\n",
    "                    default=-1,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--num-threads\",\n",
    "                    help=\"Number of threads for PyTorch (-1 to use default)\",\n",
    "                    default=-1,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--log-interval\",\n",
    "                    help=\"Overwrite log interval (default: -1, no change)\",\n",
    "                    default=-1,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--eval-freq\",\n",
    "                    help=\"Evaluate the agent every n steps (if negative, no evaluation)\",\n",
    "                    default=10000,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--eval-episodes\",\n",
    "                    help=\"Number of episodes to use for evaluation\",\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--save-freq\",\n",
    "                    help=\"Save the model every n steps (if negative, no checkpoint)\",\n",
    "                    default=-1,\n",
    "                    type=int,\n",
    "                   )\n",
    "parser.add_argument(\"--save-replay-buffer\",\n",
    "                    help=\"Save the replay buffer too (when applicable)\",\n",
    "                    action=\"store_true\",\n",
    "                    default=False,\n",
    "                   )\n",
    "parser.add_argument(\"-f\",\n",
    "                    \"--log-folder\",\n",
    "                    help=\"Log folder\",\n",
    "                    type=str,\n",
    "                    default=\"logs\",\n",
    "                   )\n",
    "parser.add_argument(\"--seed\",\n",
    "                    help=\"Random generator seed\",\n",
    "                    type=int,\n",
    "                    default=-1,\n",
    "                   )\n",
    "parser.add_argument(\"--vec-env\",\n",
    "                    help=\"VecEnv type\",\n",
    "                    type=str,\n",
    "                    default=\"dummy\",\n",
    "                    choices=[\"dummy\", \"subproc\"],\n",
    "                   )\n",
    "parser.add_argument(\"--n-trials\",\n",
    "                    help=\"Number of trials for optimizing hyperparameters\",\n",
    "                    type=int,\n",
    "                    default=10,\n",
    "                   )\n",
    "parser.add_argument(\"-optimize\",\n",
    "                    \"--optimize-hyperparameters\",\n",
    "                    action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help=\"Run hyperparameters search\",\n",
    "                   )\n",
    "parser.add_argument(\"--n-jobs\",\n",
    "                    help=\"Number of parallel jobs when optimizing hyperparameters\",\n",
    "                    type=int,\n",
    "                    default=1,\n",
    "                   )\n",
    "parser.add_argument(\"--sampler\",\n",
    "                    help=\"Sampler to use when optimizing hyperparameters\",\n",
    "                    type=str,\n",
    "                    default=\"tpe\",\n",
    "                    choices=[\"random\", \"tpe\", \"skopt\"],\n",
    "                   )\n",
    "parser.add_argument(\"--pruner\",\n",
    "                    help=\"Pruner to use when optimizing hyperparameters\",\n",
    "                    type=str,\n",
    "                    default=\"median\",\n",
    "                    choices=[\"halving\", \"median\", \"none\"],\n",
    "                   )\n",
    "parser.add_argument(\"--n-startup-trials\",\n",
    "                    help=\"Number of trials before using optuna sampler\",\n",
    "                    type=int, \n",
    "                    default=10,\n",
    "                   )\n",
    "parser.add_argument(\"--n-evaluations\",\n",
    "                    help=\"Number of evaluations for hyperparameter optimization\",\n",
    "                    type=int,\n",
    "                    default=20,\n",
    "                   )\n",
    "parser.add_argument(\"--storage\",\n",
    "                    help=\"Database storage path if distributed optimization should be used\",\n",
    "                    type=str,\n",
    "                    default=None,\n",
    "                   )\n",
    "parser.add_argument(\"--study-name\",\n",
    "                    help=\"Study name for distributed optimization\",\n",
    "                    type=str,\n",
    "                    default=None,\n",
    "                   )\n",
    "parser.add_argument(\"--verbose\",\n",
    "                    help=\"Verbose mode (0: no output, 1: INFO)\",\n",
    "                    default=0, \n",
    "                    type=int)\n",
    "parser.add_argument(\"--gym-packages\",\n",
    "                    type=str,\n",
    "                    nargs=\"+\",\n",
    "                    default=[],\n",
    "                    help=\"Additional eve Gym environment package modules to import\"\n",
    "                         \"(e.g. gym_minigrid)\",\n",
    "                   )\n",
    "parser.add_argument(\"--env-kwargs\",\n",
    "                    type=str,\n",
    "                    nargs=\"+\",\n",
    "                    action=StoreDict,\n",
    "                    help=\"Optional keyword argument to pass to the env constructor\"\n",
    "                         \"Discard! Manually defined in latter.\",\n",
    "                   )\n",
    "parser.add_argument(\"-params\",\n",
    "                    \"--hyperparams\",\n",
    "                    type=str,\n",
    "                    nargs=\"+\",\n",
    "                    action=StoreDict,\n",
    "                    help=\"Overwrite hyperparameter (e.g. learning_rate:0.01)\",\n",
    "                   )\n",
    "parser.add_argument(\"-uuid\",\n",
    "                    \"--uuid\",\n",
    "                    action=\"store_true\",\n",
    "                    default=False,\n",
    "                    help=\"Ensure that the run has a unique ID.\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Create env_kwargs here\n",
    "# the following parameters is used to define a trainer for env.\n",
    "args.env_kwargs = dict(\n",
    "    trainer_id=\"mnist\",\n",
    "    checkpoint_path=\"/media/densechen/data/code/eve/examples/mnist.pt\",\n",
    "    max_timesteps=1, # keep 1 for non-spiking mode.\n",
    "    data_kwargs={\n",
    "        \"root\": \"/media/densechen/data/dataset\",\n",
    "    },\n",
    "    kwargs={\n",
    "        \"device\": \"cuda:0\",\n",
    "        \"root_dir\": \"/media/densechen/data/code/eve/examples\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# rewrite log floder.\n",
    "args.log_folder = \"/media/densechen/data/code/eve/examples/logs\"\n",
    "\n",
    "pprint(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== FixedNas-v0 ==========\n",
      "Seed: 1460492072\n"
     ]
    }
   ],
   "source": [
    "# Going through custom gym packages to let them register in the global registory\n",
    "for env_module in args.gym_packages:\n",
    "    importlib.import_module(env_module)\n",
    "\n",
    "env_id = args.env\n",
    "registered_envs = set(gym.envs.registry.env_specs.keys())\n",
    "# If the environment is not found, suggest the closest math\n",
    "if env_id not in registered_envs:\n",
    "    try:\n",
    "        closest_match = difflib.get_close_matches(env_id, \n",
    "                                                  registered_envs,\n",
    "                                                  n=1)[0]\n",
    "    except IndexError:\n",
    "        closest_match = \"no close match found...\"\n",
    "    raise ValueError(\n",
    "        r\"{env_id} not found in gym registry, you maybe meant {closest_match}\"\n",
    "    )\n",
    "\n",
    "# Unique id to ensure there is no race condition for the folder creation\n",
    "uuid_str = f\"_{uuid.uuid4()}\" if args.uuid else \"\"\n",
    "if args.seed < 0:\n",
    "    # Seed but with a random one.\n",
    "    args.seed = np.random.randint(2 ** 32 - 1, dtype=\"int64\").item()\n",
    "\n",
    "set_random_seed(args.seed)\n",
    "\n",
    "# Setting num threads to 1 makes things run faster on cpu.\n",
    "if args.num_threads > 0:\n",
    "    if args.verbose > 0:\n",
    "        pprint(f\"Setting torch.num_threads to {args.num_threads}\")\n",
    "        torch.set_num_threads(args.num_threads)\n",
    "\n",
    "if args.trained_agent != \"\":\n",
    "    assert args.trained_agent.endswith(\".zip\") and os.path.isfile(args.trained_agent), \\\n",
    "        \"The trained_agent must be a valid path to a .zip fle.\"\n",
    "print(\"=\" * 10, env_id, \"=\" * 10)\n",
    "print(f\"Seed: {args.seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the ExperimentManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_manager = ExperimentManager(\n",
    "    args,\n",
    "    args.algo,\n",
    "    env_id,\n",
    "    args.log_folder,\n",
    "    args.tensorboard_log,\n",
    "    args.n_timesteps,\n",
    "    args.eval_freq,\n",
    "    args.eval_episodes,\n",
    "    args.save_freq,\n",
    "    args.hyperparams,\n",
    "    args.env_kwargs,\n",
    "    args.trained_agent,\n",
    "    args.optimize_hyperparameters,\n",
    "    args.storage,\n",
    "    args.study_name,\n",
    "    args.n_trials,\n",
    "    args.n_jobs,\n",
    "    args.sampler,\n",
    "    args.pruner,\n",
    "    n_startup_trials=args.n_startup_trials,\n",
    "    n_evaluations=args.n_evaluations,\n",
    "    truncate_last_trajectory=args.truncate_last_trajectory,\n",
    "    uuid_str=uuid_str,\n",
    "    seed=args.seed,\n",
    "    log_interval=args.log_interval,\n",
    "    save_replay_buffer=args.save_replay_buffer,\n",
    "    verbose=args.verbose,\n",
    "    vec_env_type=args.vec_env,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: mnist ({'checkpoint_path': \"\n",
      " \"'/media/densechen/data/code/eve/examples/mnist.pt', 'max_timesteps': 1, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve/examples'}})\")\n",
      "original accuracy: 0.893690664556962\n",
      "create an upgrader automatically\n",
      "(\"making new trainer: mnist ({'checkpoint_path': \"\n",
      " \"'/media/densechen/data/code/eve/examples/mnist.pt', 'max_timesteps': 1, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve/examples'}})\")\n",
      "original accuracy: 0.893690664556962\n",
      "create an upgrader automatically\n",
      "Applying normal noise with std 0.1\n",
      "Log path: /media/densechen/data/code/eve/examples/logs/ddpg/FixedNas-v0_2\n"
     ]
    }
   ],
   "source": [
    "model = exp_manager.setup_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original acc: 0.893690664556962  vs. rl acc: 0.8918117088607594\n",
      "Saving to /media/densechen/data/code/eve/examples/logs/ddpg/FixedNas-v0_2\n"
     ]
    }
   ],
   "source": [
    "# Normal training\n",
    "if model is not None:\n",
    "    exp_manager.learn(model)\n",
    "    exp_manager.save_trained_model(model)\n",
    "else:\n",
    "    exp_manager.hyperparameters_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the tensorboard log folder, and run ```tensorboard --logdir .``` to see the trianing log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
