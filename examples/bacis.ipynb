{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eve: Make Deep Learning More Interesting\n",
    "\n",
    "Before starting, please make sure **Eve** is in your python path.\n",
    "\n",
    "You can install **Eve** via PyPi by ```pip install eve-ml```, \n",
    "\n",
    "then check it out by ```python -c \"import eve; print(eve.__version__)\"```.\n",
    "\n",
    "Now, let's learn more about **Eve**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eve is a native extension of PyTorch\n",
    "\n",
    "The core module of Eve is **eve.cores.Eve**, which succeed **torch.nn.Module**.\n",
    "\n",
    "You can build a deep learning network with **Eve** just like what you used to do with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eve\n",
    "import torch\n",
    "import eve.cores\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a toy model using **Eve** to solve MNIST classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use new features of Eve, you must ensure the network succeed Eve, not nn.Module\n",
    "class ToyModel(eve.cores.Eve):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # You can define any nn.Module in Eve, Eve can handle them well.\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(3),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.linear = torch.nn.Linear(14 * 14 * 3, 10)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        conv = self.conv(x)\n",
    "        \n",
    "        conv = torch.flatten(conv, 1)\n",
    "        linear = self.linear(conv)\n",
    "        return torch.log_softmax(linear, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset and define dataloader. **data_root** is what the MNIST dataset will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/media/densechen/data/dataset\"\n",
    "\n",
    "# define dataset\n",
    "train_dataset = MNIST(root=data_root, train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset = MNIST(root=data_root, train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# define dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=2, batch_size=128, drop_last=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, num_workers=2, batch_size=128, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the network and optimizer, and move them to cuda if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda\n"
     ]
    }
   ],
   "source": [
    "# define network\n",
    "toy_model = ToyModel()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    toy_model.cuda()\n",
    "    print(\"Use cuda\")\n",
    "else:\n",
    "    print(\"Use cpu\")\n",
    "    \n",
    "# define optimzier\n",
    "# !WARN: in any case, you should call model.torch_parameters() to gather the parameters needed for optimizer.\n",
    "optimizer = torch.optim.Adam(toy_model.torch_parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train toy_model in dataset for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on Epoch 1/10 is 91.21%\n",
      "Acc on Epoch 2/10 is 92.32%\n",
      "Acc on Epoch 3/10 is 93.25%\n",
      "Acc on Epoch 4/10 is 94.00%\n",
      "Acc on Epoch 5/10 is 94.62%\n",
      "Acc on Epoch 6/10 is 94.99%\n",
      "Acc on Epoch 7/10 is 95.29%\n",
      "Acc on Epoch 8/10 is 95.52%\n",
      "Acc on Epoch 9/10 is 95.86%\n",
      "Acc on Epoch 10/10 is 95.77%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    toy_model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.nn.functional.cross_entropy(toy_model(data), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    correct = 0.0\n",
    "    toy_model.eval()\n",
    "    for data, target in test_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        predict = toy_model(data)\n",
    "        correct += (predict.max(dim=1)[1] == target).float().sum()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * correct/len(test_dataset):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization Neural Network\n",
    "\n",
    "**Eve** supports many quantization methods, which is developed recently.\n",
    "\n",
    "Now, let's design a STE quantization model to solve the MNIST classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use new features of Eve, you must ensure the network succeed Eve, not nn.Module\n",
    "class SteToyModel(eve.cores.Eve):\n",
    "    def __init__(self, max_bit_width=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # You can define any nn.Module in Eve, Eve can handle them well.\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(3),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        state = eve.cores.State(self.conv)\n",
    "        self.ste = eve.cores.SteQuan(state=state, max_bit_width=max_bit_width)\n",
    "        \n",
    "        self.linear = torch.nn.Linear(14 * 14 * 3, 10)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        conv = self.conv(x)\n",
    "        \n",
    "        ste = self.ste(conv)\n",
    "        \n",
    "        ste = torch.flatten(ste, 1)\n",
    "        linear = self.linear(ste)\n",
    "        return torch.log_softmax(linear, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an STE toy model and optimizer, and move them to cuda if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda\n"
     ]
    }
   ],
   "source": [
    "# define network\n",
    "ste_toy_model = SteToyModel(max_bit_width=4)\n",
    "\n",
    "if use_cuda:\n",
    "    ste_toy_model.cuda()\n",
    "    print(\"Use cuda\")\n",
    "else:\n",
    "    print(\"Use cpu\")\n",
    "    \n",
    "# define optimzier\n",
    "optimizer = torch.optim.Adam(ste_toy_model.torch_parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ste_toy_model in dataset for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on Epoch 1/10 is 89.87%\n",
      "Acc on Epoch 2/10 is 91.02%\n",
      "Acc on Epoch 3/10 is 91.63%\n",
      "Acc on Epoch 4/10 is 91.84%\n",
      "Acc on Epoch 5/10 is 91.83%\n",
      "Acc on Epoch 6/10 is 91.72%\n",
      "Acc on Epoch 7/10 is 91.79%\n",
      "Acc on Epoch 8/10 is 91.79%\n",
      "Acc on Epoch 9/10 is 91.93%\n",
      "Acc on Epoch 10/10 is 91.95%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    ste_toy_model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.nn.functional.cross_entropy(ste_toy_model(data), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    correct = 0.0\n",
    "    ste_toy_model.eval()\n",
    "    for data, target in test_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        predict = ste_toy_model(data)\n",
    "        correct += (predict.max(dim=1)[1] == target).float().sum()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * correct/len(test_dataset):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use a max_bit_width = 4 to do the quantization operation, and we find that by quantization, the \n",
    "performance of model can be further improved. This is also a special property of Quantization.\n",
    "\n",
    "We think that the quantization operation is benifit for improving generalization ability of model compared \n",
    "with full-precision network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiking Neural Network\n",
    "\n",
    "**Eve** designs some special attributes to support hidden states rather than **torch.nn.Buffer**.\n",
    "\n",
    "The hidden states of **Eve** will reset while calling **Eve.reset()** and will not be fetched by state_dict()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnnToyModel(eve.cores.Eve):\n",
    "    def __init__(self, max_timesteps=5):\n",
    "        \"\"\"Different with traditional neural network, spiking neural network should repeat many times for a specifed \n",
    "        input image.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # recored the max timesteps\n",
    "        self.max_timesteps = max_timesteps\n",
    "        \n",
    "        # For spiking neural network, you should specified a encoder for it to transfer the rate encoding to\n",
    "        # spiking trains. Here, we use the possion encoder just likes many spiking neural networks do.\n",
    "        self.encoder = eve.cores.PoissonEncoder(max_timesteps=max_timesteps)\n",
    "        \n",
    "        # You can define any nn.Module in Eve, Eve can handle them well.\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride=2, padding=1),\n",
    "            torch.nn.BatchNorm2d(3),\n",
    "            # torch.nn.ReLU(), # move the ReLU to Node already\n",
    "        )\n",
    "        \n",
    "        state = eve.cores.State(self.conv) # get some necessary argments to define a quan layer\n",
    "        \n",
    "        # add a IfNode\n",
    "        self.ifnode = eve.cores.IfNode(state=state, time_independent=False)\n",
    "        \n",
    "        # add a ste layer to convert the voltage into spiking signals.\n",
    "        self.ste = eve.cores.SteQuan(state=state, max_bit_width=1)\n",
    "        self.linear = torch.nn.Linear(14 * 14 * 3, 10)\n",
    "        \n",
    "        self.spike() # turn on spiking mode\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # NOTE: spiking neural network contains hidden states of voltage we should reset it every time.\n",
    "        self.reset()\n",
    "        \n",
    "        res = []\n",
    "        for i in range(self.max_timesteps):\n",
    "            conv = self.conv(x)\n",
    "            \n",
    "            ifnode = self.ifnode(conv)\n",
    "            \n",
    "            # insert ste layer here\n",
    "            ste = self.ste(ifnode)\n",
    "            \n",
    "            ste = torch.flatten(ste, 1)\n",
    "            linear = self.linear(ste)\n",
    "            res.append(linear)\n",
    "            \n",
    "        res = torch.stack(res, dim=0).mean(dim=0)\n",
    "\n",
    "        return torch.nn.functional.log_softmax(res, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define SNN toy model and optimizer, move them to cuda if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use cuda\n"
     ]
    }
   ],
   "source": [
    "max_timesteps = 3\n",
    "snn_toy_model = SnnToyModel(max_timesteps)\n",
    "\n",
    "if use_cuda:\n",
    "    snn_toy_model.cuda()\n",
    "    print(\"use cuda\")\n",
    "else:\n",
    "    print(\"use cpu\")\n",
    "    \n",
    "optimizer = torch.optim.Adam(snn_toy_model.torch_parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train snn_toy_model in dataset for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc on Epoch 1/10 is 89.33%\n",
      "Acc on Epoch 2/10 is 90.84%\n",
      "Acc on Epoch 3/10 is 91.42%\n",
      "Acc on Epoch 4/10 is 91.94%\n",
      "Acc on Epoch 5/10 is 92.21%\n",
      "Acc on Epoch 6/10 is 92.22%\n",
      "Acc on Epoch 7/10 is 92.29%\n",
      "Acc on Epoch 8/10 is 92.25%\n",
      "Acc on Epoch 9/10 is 92.42%\n",
      "Acc on Epoch 10/10 is 92.55%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    snn_toy_model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.nn.functional.cross_entropy(snn_toy_model(data), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    correct = 0.0\n",
    "    snn_toy_model.eval()\n",
    "    for data, target in test_dataloader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        predict = snn_toy_model(data)\n",
    "        correct += (predict.max(dim=1)[1] == target).float().sum()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * correct/len(test_dataset):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the performance of spiking neural network is still have a large space to be improved. \n",
    "At this example, you can increase the max_timesteps to increase the final accuracy.\n",
    "\n",
    "\n",
    "You can fetch all the hidden states of **Eve** via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ifnode.voltage_hid torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "for k, hid in snn_toy_model.named_hidden_states():\n",
    "    print(k, torch.typename(hid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quan\n",
    "\n",
    "The following cells, we use the trainer provied by **Eve** to study on the different quantization methods' performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: mnist ({'checkpoint_path': '', 'max_timesteps': 1, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve-mli/examples/logs'}, 'net_arch_kwargs': \"\n",
      " \"{'quan': 'SteQuan', 'quan_kwargs': {'max_bit_width': 4}}, \"\n",
      " \"'optimizer_kwargs': {'lr': 0.001}})\")\n",
      "falied to load checkpoint , raise [Errno 2] No such file or directory: ''\n",
      "original accuracy: 0.10848496835443038\n",
      "create an upgrader automatically\n",
      "SteQuan\n",
      "Acc on Epoch 1/10 is 89.60%\n",
      "Acc on Epoch 2/10 is 91.46%\n",
      "Acc on Epoch 3/10 is 92.09%\n",
      "Acc on Epoch 4/10 is 92.50%\n",
      "Acc on Epoch 5/10 is 92.37%\n",
      "Acc on Epoch 6/10 is 92.38%\n",
      "Acc on Epoch 7/10 is 92.43%\n",
      "Acc on Epoch 8/10 is 92.53%\n",
      "Acc on Epoch 9/10 is 92.49%\n",
      "Acc on Epoch 10/10 is 92.36%\n"
     ]
    }
   ],
   "source": [
    "from eve.app import make\n",
    "\n",
    "mnist_trainer = make(\"mnist\", \n",
    "                     checkpoint_path=\"\", \n",
    "                     max_timesteps=1, \n",
    "                     data_kwargs={\"root\": \"/media/densechen/data/dataset\"}, \n",
    "                     kwargs={\n",
    "                        \"device\": \"cuda:0\",\n",
    "                        \"root_dir\": \"/media/densechen/data/code/eve-mli/examples/logs\"\n",
    "                        },\n",
    "                     net_arch_kwargs={\n",
    "                        \"quan\": \"SteQuan\",  \n",
    "                        \"quan_kwargs\":{\n",
    "                            \"max_bit_width\": 4,\n",
    "                        },\n",
    "                     },\n",
    "                     optimizer_kwargs={\n",
    "                         \"lr\": 1e-3,\n",
    "                     },\n",
    "                    )\n",
    "print(\"SteQuan\")\n",
    "for i in range(10):\n",
    "    mnist_trainer.train_one_epoch()\n",
    "    acc = mnist_trainer.test_one_epoch()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SteQuan\n",
    "\n",
    "SteQuan is the most widely used quantization function with fixed alpha parameters.\n",
    "\n",
    "SteQuan is more stable and can be trained with a larger learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: mnist ({'checkpoint_path': '', 'max_timesteps': 1, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve-mli/examples/logs'}, 'net_arch_kwargs': \"\n",
      " \"{'quan': 'LsqQuan', 'quan_kwargs': {'max_bit_width': 4}}, \"\n",
      " \"'optimizer_kwargs': {'lr': 0.001}})\")\n",
      "falied to load checkpoint , raise [Errno 2] No such file or directory: ''\n",
      "original accuracy: 0.10571598101265822\n",
      "create an upgrader automatically\n",
      "LsqQuan\n",
      "Acc on Epoch 1/10 is 91.21%\n",
      "Acc on Epoch 2/10 is 92.41%\n",
      "Acc on Epoch 3/10 is 93.11%\n",
      "Acc on Epoch 4/10 is 90.01%\n",
      "Acc on Epoch 5/10 is 11.36%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "alpha must be positive",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7d5befd42c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LsqQuan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmnist_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Acc on Epoch {i+1}/10 is {100 * acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/app/trainer.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meve_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/app/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/app/trainer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspiking_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnon_spiking_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/app/trainer.py\u001b[0m in \u001b[0;36mnon_spiking_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \"\"\"Implements non spiking forward pass.\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/app/mnist/mnist.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mcdt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdt1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mcdt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlinear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/cores/quan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/cores/quan.py\u001b[0m in \u001b[0;36mquan\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbit_width_eve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/eve_mli-0.0.1rc0-py3.8.egg/eve/cores/quan.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, x, alpha, bit_width)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbit_width\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha must be positive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         quan_x = quantize(x, alpha, torch.zeros_like(alpha), 2**bit_width - 1,\n",
      "\u001b[0;31mValueError\u001b[0m: alpha must be positive"
     ]
    }
   ],
   "source": [
    "from eve.app import make\n",
    "\n",
    "mnist_trainer = make(\"mnist\", \n",
    "                     checkpoint_path=\"\", \n",
    "                     max_timesteps=1, \n",
    "                     data_kwargs={\"root\": \"/media/densechen/data/dataset\"}, \n",
    "                     kwargs={\n",
    "                        \"device\": \"cuda:0\",\n",
    "                        \"root_dir\": \"/media/densechen/data/code/eve-mli/examples/logs\"\n",
    "                        },\n",
    "                     net_arch_kwargs={\n",
    "                        \"quan\": \"LsqQuan\",  \n",
    "                        \"quan_kwargs\":{\n",
    "                            \"max_bit_width\": 4,\n",
    "                        },\n",
    "                     },\n",
    "                     optimizer_kwargs={\n",
    "                         \"lr\": 1e-3,\n",
    "                     },\n",
    "                    )\n",
    "print(\"LsqQuan\")\n",
    "for i in range(10):\n",
    "    mnist_trainer.train_one_epoch()\n",
    "    acc = mnist_trainer.test_one_epoch()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LsqQuan\n",
    "\n",
    "LsqQuan has a trainable alpha parameter, which is supervised with global error.\n",
    "It is unstable during training and prunes to make a invalid alpha value, which is not a positive one.\n",
    "Using a smaller learning rate is vital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: mnist ({'checkpoint_path': '', 'max_timesteps': 1, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve-mli/examples/logs'}, 'net_arch_kwargs': \"\n",
      " \"{'quan': 'LlsqQuan', 'quan_kwargs': {'max_bit_width': 4}}, \"\n",
      " \"'optimizer_kwargs': {'lr': 0.001}})\")\n",
      "falied to load checkpoint , raise [Errno 2] No such file or directory: ''\n",
      "original accuracy: 0.08662974683544304\n",
      "create an upgrader automatically\n",
      "LlsqQuan\n",
      "Acc on Epoch 1/10 is 92.34%\n",
      "Acc on Epoch 2/10 is 94.48%\n",
      "Acc on Epoch 3/10 is 95.33%\n",
      "Acc on Epoch 4/10 is 95.40%\n",
      "Acc on Epoch 5/10 is 95.06%\n",
      "Acc on Epoch 6/10 is 93.93%\n",
      "Acc on Epoch 7/10 is 93.44%\n",
      "Acc on Epoch 8/10 is 93.08%\n",
      "Acc on Epoch 9/10 is 92.94%\n",
      "Acc on Epoch 10/10 is 92.70%\n"
     ]
    }
   ],
   "source": [
    "from eve.app import make\n",
    "mnist_trainer = make(\"mnist\", \n",
    "                     checkpoint_path=\"\", \n",
    "                     max_timesteps=1, \n",
    "                     data_kwargs={\"root\": \"/media/densechen/data/dataset\"}, \n",
    "                     kwargs={\n",
    "                        \"device\": \"cuda:0\",\n",
    "                        \"root_dir\": \"/media/densechen/data/code/eve-mli/examples/logs\"\n",
    "                        },\n",
    "                     net_arch_kwargs={\n",
    "                        \"quan\": \"LlsqQuan\", \n",
    "                        \"quan_kwargs\":{\n",
    "                            \"max_bit_width\": 4,\n",
    "                        },\n",
    "                     },\n",
    "                     optimizer_kwargs={\n",
    "                         \"lr\": 1e-3,\n",
    "                     },\n",
    "                    )\n",
    "print(\"LlsqQuan\")\n",
    "for i in range(10):\n",
    "    mnist_trainer.train_one_epoch()\n",
    "    acc = mnist_trainer.test_one_epoch()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlsqQuan\n",
    "\n",
    "LlsqQuan has a trainable alpha parameter, which is supervised with local error. It is more stable than LsqQuan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Spiking and Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"making new trainer: mnist ({'checkpoint_path': '', 'max_timesteps': 5, \"\n",
      " \"'data_kwargs': {'root': '/media/densechen/data/dataset'}, 'kwargs': \"\n",
      " \"{'device': 'cuda:0', 'root_dir': \"\n",
      " \"'/media/densechen/data/code/eve-mli/examples/logs'}, 'net_arch_kwargs': \"\n",
      " \"{'quan': 'SteQuan', 'quan_kwargs': {'max_bit_width': 4}}, \"\n",
      " \"'optimizer_kwargs': {'lr': 0.001}})\")\n",
      "falied to load checkpoint , raise [Errno 2] No such file or directory: ''\n",
      "original accuracy: 0.08910205696202532\n",
      "create an upgrader automatically\n",
      "QuanSpiking\n",
      "Acc on Epoch 1/10 is 89.33%\n",
      "Acc on Epoch 2/10 is 90.93%\n",
      "Acc on Epoch 3/10 is 92.13%\n",
      "Acc on Epoch 4/10 is 92.41%\n",
      "Acc on Epoch 5/10 is 92.66%\n",
      "Acc on Epoch 6/10 is 92.90%\n",
      "Acc on Epoch 7/10 is 92.80%\n",
      "Acc on Epoch 8/10 is 92.81%\n",
      "Acc on Epoch 9/10 is 93.02%\n",
      "Acc on Epoch 10/10 is 93.02%\n"
     ]
    }
   ],
   "source": [
    "from eve.app import make\n",
    "mnist_trainer = make(\"mnist\", \n",
    "                     checkpoint_path=\"\", \n",
    "                     max_timesteps=5, \n",
    "                     data_kwargs={\"root\": \"/media/densechen/data/dataset\"}, \n",
    "                     kwargs={\n",
    "                        \"device\": \"cuda:0\",\n",
    "                        \"root_dir\": \"/media/densechen/data/code/eve-mli/examples/logs\"\n",
    "                        },\n",
    "                     net_arch_kwargs={\n",
    "                        \"quan\": \"SteQuan\", \n",
    "                        \"quan_kwargs\":{\n",
    "                            \"max_bit_width\": 4,\n",
    "                        },\n",
    "                     },\n",
    "                     optimizer_kwargs={\n",
    "                         \"lr\": 1e-3,\n",
    "                     },\n",
    "                    )\n",
    "print(\"QuanSpiking\")\n",
    "mnist_trainer.eve_module.spike()\n",
    "for i in range(10):\n",
    "    mnist_trainer.train_one_epoch()\n",
    "    acc = mnist_trainer.test_one_epoch()\n",
    "    print(f\"Acc on Epoch {i+1}/10 is {100 * acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
